# 财务数据爬虫

从巨潮资讯网爬取上市公司财务报告中的"数据资源"信息，并生成Excel报告。

## 功能特点

- 🚀 自动爬取指定日期范围内的财务报告PDF
- 📊 智能解析PDF中的"数据资源"相关数据
- 📈 生成长格式和宽格式的Excel报告
- 🔄 支持多线程并发处理，提高效率
- 📁 自动创建文件夹保存PDF文件
- ⏭️ 跳过已存在的文件，避免重复下载

## 安装依赖

```bash
pip install -r requirements.txt
```

## 使用方法

### 基本使用

```bash
python financial_data_crawler.py
```

### 修改爬取参数

在 `main()` 函数中可以修改以下参数：

```python
# 修改日期范围
start_date = datetime(2025, 1, 1)  # 开始日期
end_date = datetime(2025, 6, 30)   # 结束日期

# 修改报告类型
report_category = "category_yjdbg_szsh"  # 季度报告
# 其他可选类型：
# "category_ndbg_szsh"  # 年度报告
# "category_bndbg_szsh" # 半年度报告
```

## 输出文件

程序会生成以下文件：

1. **数据资源提取结果.xlsx** - 长格式数据，包含所有提取的原始数据
2. **最终宽格式报告.xlsx** - 宽格式数据，便于分析
3. **FinancialReports_Final/** - 保存下载的PDF文件

## 数据结构

### 长格式数据列
- 公司名称
- 报告名称  
- 报告日期
- 项目名称（存货/无形资产/开发支出）
- 金额
- 源文件

### 宽格式数据列
- 公司名称
- 报告名称
- 报告日期
- 无形资产
- 开发支出
- 存货
- 源文件

## 注意事项

1. 程序会自动创建 `FinancialReports_Final` 文件夹保存PDF文件
2. 如果PDF文件已存在，会跳过下载
3. 程序使用多线程处理，请确保网络连接稳定
4. 建议在非高峰时段运行，避免对服务器造成压力

## 错误处理

- 网络错误会自动重试
- PDF解析错误会记录并继续处理
- 程序会显示详细的进度信息

## 系统要求

- Python 3.7+
- 稳定的网络连接
- 足够的磁盘空间存储PDF文件

## 许可证

本项目仅供学习和研究使用。
