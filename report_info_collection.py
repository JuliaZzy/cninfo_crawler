#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šä¿¡æ¯æ”¶é›†å™¨ - ä»CSVæ–‡ä»¶è¯»å–PDFé“¾æ¥å¹¶æå–æ•°æ®èµ„æºä¿¡æ¯

åŠŸèƒ½ï¼š
1. ä»CSVæ–‡ä»¶ä¸­è¯»å–PDFé“¾æ¥
2. é€ä¸ªè§£æPDFï¼Œæå–"å­˜è´§", "æ— å½¢èµ„äº§", "å¼€å‘æ”¯å‡º"çš„æ•°æ®
3. ç”Ÿæˆé•¿æ ¼å¼å’Œå®½æ ¼å¼çš„ExcelæŠ¥å‘Š
4. æ·»åŠ "æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§"æ ‡è®°åˆ—

ä½œè€…ï¼šåŸºäºfinancial_data_crawler.pyè½¬æ¢
æ—¥æœŸï¼š2025å¹´
"""

import os
import re
import requests
import pandas as pd
import pdfplumber
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from datetime import datetime
import warnings
import logging
from pathlib import Path
import glob
import argparse

# æŠ‘åˆ¶pdfplumberçš„è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=UserWarning, module="pdfplumber")
logging.getLogger("pdfplumber").setLevel(logging.ERROR)


def extract_data_by_category(pdf_content, pdf_url):
    """
    é€šè¿‡è§£æPDFä¸­çš„è¡¨æ ¼ç»“æ„æ¥æå–æ•°æ®ï¼Œèƒ½å¤Ÿç²¾ç¡®åŒºåˆ†åˆ—ï¼Œé¿å…è¯¯æŠ“ã€‚
    
    Args:
        pdf_content (bytes): PDFæ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
        pdf_url (str): PDFæ–‡ä»¶çš„URLï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        list: åŒ…å«æå–æ•°æ®çš„å­—å…¸åˆ—è¡¨
    """
    found_items = []
    parent_categories = ["å­˜è´§", "æ— å½¢èµ„äº§", "å¼€å‘æ”¯å‡º"]
    # ç”¨äºå»é‡çš„é›†åˆï¼Œè®°å½•å·²ç»æ‰¾åˆ°çš„ç±»åˆ«
    found_categories = set()
    
    def find_first_number_in_row(row, start_col=1):
        """
        åœ¨è¡Œçš„æŒ‡å®šåˆ—å¼€å§‹ä½ç½®æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ•°å­—
        
        Args:
            row (list): è¡¨æ ¼è¡Œæ•°æ®
            start_col (int): å¼€å§‹æŸ¥æ‰¾çš„åˆ—ç´¢å¼•
            
        Returns:
            tuple: (æ‰¾åˆ°çš„æ•°å­—, æ˜¯å¦æ£€æµ‹åˆ°æ•°å­—)
        """
        has_number = False
        found_value = "ç©ºå€¼"
        
        for i in range(start_col, len(row)):
            cell_value = row[i]
            if cell_value and isinstance(cell_value, str):
                # æ¸…ç†å•å…ƒæ ¼å†…å®¹ï¼Œå»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
                cleaned_value = cell_value.strip().replace(' ', '')
                
                # æ›´å®½æ¾çš„æ•°å­—åŒ¹é…æ¨¡å¼ï¼ŒåŒ…æ‹¬å„ç§æ ¼å¼
                number_patterns = [
                    r'((?:\d{1,3},)*\d{1,3}\.\d{2})',  # æ ‡å‡†æ ¼å¼ï¼š1,234.56
                    r'((?:\d{1,3},)*\d+)',              # æ•´æ•°æ ¼å¼ï¼š1,234
                    r'(\d+\.\d{2})',                    # ç®€å•å°æ•°ï¼š123.45
                    r'(\d+)',                           # çº¯æ•°å­—ï¼š123
                    r'(-)',                             # è´Ÿå·æˆ–ç©ºå€¼æ ‡è®°
                ]
                
                for pattern in number_patterns:
                    match = re.search(pattern, cleaned_value)
                    if match:
                        found_value = match.group(1)
                        has_number = True
                        break
                
                if has_number:
                    break
        
        return found_value, has_number
    
    try:
        # ä¸´æ—¶æŠ‘åˆ¶pdfplumberçš„è­¦å‘Š
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            with pdfplumber.open(BytesIO(pdf_content)) as pdf:
                for page in pdf.pages:
                    # å°è¯•æå–é¡µé¢ä¸Šçš„æ‰€æœ‰è¡¨æ ¼
                    tables = page.extract_tables()
                    if not tables:
                        continue

                    for table in tables:
                        last_parent_item = None
                        # éå†è¡¨æ ¼çš„æ¯ä¸€è¡Œ
                        for row in table:
                            if not row or not row[0]:  # è·³è¿‡ç©ºè¡Œæˆ–ç¬¬ä¸€åˆ—ä¸ºç©ºçš„è¡Œ
                                continue
                            
                            # æ¸…ç†ç¬¬ä¸€åˆ—çš„æ–‡æœ¬ï¼Œå»é™¤æ¢è¡Œç¬¦
                            first_col_text = row[0].replace('\n', '')

                            # æ­¥éª¤1: æ£€æŸ¥æ˜¯å¦ä¸ºçˆ¶é¡¹
                            is_parent = False
                            for cat in parent_categories:
                                if cat in first_col_text:
                                    last_parent_item = cat
                                    is_parent = True
                                    break
                            if is_parent:
                                continue # å¦‚æœæ˜¯çˆ¶é¡¹è¡Œï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€è¡Œ

                            # æ­¥éª¤2: æ£€æŸ¥æ˜¯å¦ä¸ºå­é¡¹ï¼Œå¹¶ä¸”æˆ‘ä»¬å·²ç»æ‰¾åˆ°äº†å®ƒçš„çˆ¶é¡¹
                            if last_parent_item and "æ•°æ®èµ„æº" in first_col_text:
                                # å»é‡æ£€æŸ¥ï¼šå¦‚æœè¿™ä¸ªç±»åˆ«å·²ç»æ‰¾åˆ°è¿‡ï¼Œè·³è¿‡
                                if last_parent_item in found_categories:
                                    continue
                                    
                                # æ­¥éª¤3: æ™ºèƒ½æŸ¥æ‰¾æ•°å­—ä½ç½®
                                found_value, has_number = find_first_number_in_row(row, start_col=1)
                                
                                if has_number:
                                    print(f"    âœ… {last_parent_item}æ•°æ®èµ„æº: {found_value}")
                                else:
                                    print(f"    âš ï¸ {last_parent_item}æ•°æ®èµ„æº: æœªæ£€æµ‹åˆ°æ•°å­—")

                                found_items.append({
                                    "category": last_parent_item,
                                    "value": found_value,
                                    "has_data": 1 if has_number and found_value != "ç©ºå€¼" and found_value != "-" else 0
                                })
                                # è®°å½•å·²æ‰¾åˆ°çš„ç±»åˆ«ï¼Œé¿å…é‡å¤
                                found_categories.add(last_parent_item)
                                # é‡ç½®çˆ¶é¡¹ï¼Œé¿å…ä¸‹ä¸€è¡Œçš„å…¶ä»–"å…¶ä¸­"é¡¹è¢«é”™è¯¯å½’ç±»
                                last_parent_item = None

    except Exception as e:
        print(f"    âŒ è§£æPDFè¡¨æ ¼æ—¶å‡ºé”™: {e}")
        return []
        
    if not found_items:
        print(f"    âš ï¸ åœ¨æ­¤PDFçš„ä»»ä½•è¡¨æ ¼ä¸­æœªæ‰¾åˆ°'æ•°æ®èµ„æº'ç›¸å…³æ¡ç›®ã€‚")
        
    return found_items


def process_pdf_link(row_data, session, headers, folder_path, download_pdf=True):
    """
    å¤„ç†å•ä¸ªPDFé“¾æ¥ï¼Œä¸‹è½½å¹¶è§£ææ•°æ®
    
    Args:
        row_data (dict): CSVè¡Œæ•°æ®ï¼ŒåŒ…å«PDFé“¾æ¥ç­‰ä¿¡æ¯
        session (requests.Session): è¯·æ±‚ä¼šè¯
        headers (dict): è¯·æ±‚å¤´
        folder_path (str): ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„
        download_pdf (bool): æ˜¯å¦ä¸‹è½½PDFæ–‡ä»¶åˆ°æœ¬åœ°
    
    Returns:
        list: è§£æç»“æœåˆ—è¡¨
    """
    pdf_url = row_data.get('PDFé“¾æ¥', '')
    if not pdf_url:
        print(f"  âŒ è·³è¿‡ï¼šæ— PDFé“¾æ¥")
        return []
    
    sec_code = row_data.get('è‚¡ç¥¨ä»£ç ', row_data.get('è¯åˆ¸ä»£ç ', 'æœªçŸ¥ä»£ç '))
    sec_name = row_data.get('å…¬å¸åç§°', 'æœªçŸ¥å…¬å¸')
    report_title = row_data.get('è´¢æŠ¥åç§°', 'æœªçŸ¥æŠ¥å‘Š')
    report_date = row_data.get('æŠ¥å‘Šæ—¥æœŸ', 'æœªçŸ¥æ—¥æœŸ')
    
    # æ¸…ç†å¹¶æ„é€ æ–‡ä»¶å
    report_name_base = f"{sec_name}ï¼š{report_title}_[{report_date}]"
    file_name = re.sub(r'[\\/:*?"<>|]', '_', report_name_base) + ".pdf"
    file_path = os.path.join(folder_path, file_name)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆä»…åœ¨ä¸‹è½½PDFæ¨¡å¼ä¸‹æ£€æŸ¥ï¼‰
    if download_pdf and os.path.exists(file_path):
        print(f"  ğŸ“„ æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¯»å–: {file_name}")
        try:
            with open(file_path, 'rb') as f:
                pdf_content = f.read()
        except Exception as e:
            print(f"  âŒ è¯»å–å·²å­˜åœ¨æ–‡ä»¶å¤±è´¥: {e}")
            return []
    else:
        try:
            print(f"  ğŸ“¥ æ­£åœ¨ä¸‹è½½: {sec_name} - {report_title}")
            response = session.get(pdf_url, headers=headers, timeout=(15, 45))
            response.raise_for_status()
            
            # éªŒè¯æ˜¯å¦ä¸ºPDF
            if 'application/pdf' not in response.headers.get('Content-Type', ''):
                print(f"  âš ï¸ è­¦å‘Š: {file_name} ä¸æ˜¯PDFæ–‡ä»¶ã€‚")
                return []

            pdf_content = response.content

            # æ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šæ˜¯å¦ä¿å­˜PDFæ–‡ä»¶åˆ°æœ¬åœ°
            if download_pdf:
                os.makedirs(folder_path, exist_ok=True)
                with open(file_path, 'wb') as f:
                    f.write(pdf_content)
                print(f"  âœ… PDFå·²ä¿å­˜: {file_name}")
            else:
                print(f"  ğŸ“Š ä»…è§£ææ•°æ®ï¼Œæœªä¿å­˜PDF: {file_name}")
        except requests.exceptions.RequestException as e:
            print(f"  âŒ ä¸‹è½½å¤±è´¥: {e}")
            return []

    # åœ¨å†…å­˜ä¸­è§£æPDFå†…å®¹
    extracted_data = extract_data_by_category(pdf_content, pdf_url)
    
    # å°†æŠ¥å‘Šè‡ªèº«ä¿¡æ¯æ·»åŠ åˆ°æå–ç»“æœä¸­
    results_for_excel = []
    if extracted_data:
        for item in extracted_data:
            results_for_excel.append({
                "è¯åˆ¸ä»£ç ": sec_code,
                "å…¬å¸åç§°": sec_name,
                "æŠ¥å‘Šåç§°": report_title,
                "æŠ¥å‘Šæ—¥æœŸ": report_date,
                "é¡¹ç›®åç§°": item['category'],
                "é‡‘é¢": item['value'],
                "æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§": item['has_data'],
                "PDFé“¾æ¥": pdf_url
            })
    else:
        # å³ä½¿æ²¡æ‰¾åˆ°æ•°æ®ï¼Œä¹Ÿè®°å½•ä¸‰æ¡ï¼ˆå¯¹åº”ä¸‰ä¸ªé¡¹ç›®ï¼‰ï¼Œæ–¹ä¾¿è¿½æº¯
        for category in ["å­˜è´§", "æ— å½¢èµ„äº§", "å¼€å‘æ”¯å‡º"]:
            results_for_excel.append({
                "è¯åˆ¸ä»£ç ": sec_code,
                "å…¬å¸åç§°": sec_name,
                "æŠ¥å‘Šåç§°": report_title,
                "æŠ¥å‘Šæ—¥æœŸ": report_date,
                "é¡¹ç›®åç§°": category,
                "é‡‘é¢": "N/A",
                "æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§": 0,
                "PDFé“¾æ¥": pdf_url
            })
            
    return results_for_excel


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°
    """
    parser = argparse.ArgumentParser(
        description="æŠ¥å‘Šä¿¡æ¯æ”¶é›†å™¨ - ä»CSVæ–‡ä»¶è¯»å–PDFé“¾æ¥å¹¶æå–æ•°æ®èµ„æºä¿¡æ¯"
    )
    parser.add_argument(
        "--csv-file",
        type=str,
        default=None,
        help="æŒ‡å®šCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœä¸æŒ‡å®šï¼Œå°†è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„listed_companies_*.csvæ–‡ä»¶"
    )
    parser.add_argument(
        "--no-download",
        action="store_true",
        help="ä¸ä¸‹è½½PDFæ–‡ä»¶ï¼Œä»…è§£ææ•°æ®ç”ŸæˆExcelï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šæ­¤å‚æ•°ï¼Œç¨‹åºä¼šè¯¢é—®æ˜¯å¦ä¸‹è½½"
    )
    parser.add_argument(
        "--download-pdf",
        action="store_true",
        help="ä¸‹è½½PDFæ–‡ä»¶åˆ°æœ¬åœ°ï¼ˆå®Œæ•´æ¨¡å¼ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šæ­¤å‚æ•°ï¼Œç¨‹åºä¼šè¯¢é—®æ˜¯å¦ä¸‹è½½"
    )
    return parser.parse_args()


def find_csv_file(csv_file_path=None):
    """
    æŸ¥æ‰¾ç¬¦åˆå‘½åæ¨¡å¼çš„CSVæ–‡ä»¶å¹¶è§£ææ–‡ä»¶åä¿¡æ¯
    
    Args:
        csv_file_path (str, optional): æŒ‡å®šçš„CSVæ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›ï¼Œç›´æ¥ä½¿ç”¨è¯¥æ–‡ä»¶ï¼›å¦åˆ™è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„æ–‡ä»¶
    
    Returns:
        tuple: (CSVæ–‡ä»¶è·¯å¾„, è§£æä¿¡æ¯å­—å…¸) æˆ– (None, None)
    """
    # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
    if csv_file_path:
        if not os.path.exists(csv_file_path):
            print(f"âŒ æŒ‡å®šçš„CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
            return None, None
        print(f"ğŸ“„ ä½¿ç”¨æŒ‡å®šçš„CSVæ–‡ä»¶: {csv_file_path}")
        latest_file = csv_file_path
    else:
        # æŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆæ¨¡å¼çš„CSVæ–‡ä»¶
        pattern = "listed_companies_*_*.csv"
        csv_files = glob.glob(pattern)
        
        if not csv_files:
            print("âŒ æœªæ‰¾åˆ°ç¬¦åˆå‘½åæ¨¡å¼çš„CSVæ–‡ä»¶ï¼ˆlisted_companies_*_*.csvï¼‰")
            return None, None
        
        # æŒ‰æ–‡ä»¶åä¸­çš„æ—¶é—´æˆ³æ’åºï¼Œè¿”å›æœ€æ–°çš„ï¼ˆæ›´å‡†ç¡®ï¼‰
        def extract_timestamp_from_filename(filename):
            """ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³ç”¨äºæ’åº"""
            try:
                name_without_ext = os.path.basename(filename).replace('.csv', '')
                parts = name_without_ext.split('_')
                # æ–‡ä»¶åæ ¼å¼ï¼šlisted_companies_{start_date}_{end_date}_{report_type}_{timestamp}
                # timestamp æ ¼å¼é€šå¸¸æ˜¯ YYYYMMDD_HHMMSS
                if len(parts) >= 6:
                    timestamp_str = '_'.join(parts[5:])  # è·å–æ—¶é—´æˆ³éƒ¨åˆ†
                    # å°è¯•è§£ææ—¶é—´æˆ³
                    if '_' in timestamp_str:
                        date_part, time_part = timestamp_str.split('_', 1)
                        # è½¬æ¢ä¸ºå¯æ¯”è¾ƒçš„æ ¼å¼
                        return f"{date_part}_{time_part}"
                # å¦‚æœæ— æ³•è§£æï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºå¤‡é€‰
                return str(os.path.getmtime(filename))
            except:
                return str(os.path.getmtime(filename))
        
        csv_files.sort(key=extract_timestamp_from_filename, reverse=True)
        latest_file = csv_files[0]
        
        print(f"ğŸ“„ æ‰¾åˆ°CSVæ–‡ä»¶: {latest_file}")
        if len(csv_files) > 1:
            print(f"   æç¤º: æ‰¾åˆ° {len(csv_files)} ä¸ªåŒ¹é…æ–‡ä»¶ï¼Œä½¿ç”¨æœ€æ–°çš„ï¼ˆæŒ‰æ–‡ä»¶åæ—¶é—´æˆ³ï¼‰: {latest_file}")
            print(f"   å…¶ä»–æ–‡ä»¶: {', '.join(csv_files[1:3])}..." if len(csv_files) > 3 else f"   å…¶ä»–æ–‡ä»¶: {', '.join(csv_files[1:])}")
    
    # è§£ææ–‡ä»¶åï¼šlisted_companies_{start_date}_{end_date}_{report_type}_{timestamp}.csv
    file_name = os.path.basename(latest_file)
    # å»æ‰æ‰©å±•å
    name_without_ext = file_name.replace('.csv', '')
    # åˆ†å‰²æ–‡ä»¶å
    parts = name_without_ext.split('_')
    
    if len(parts) >= 5:
        # listed_companies_{start_date}_{end_date}_{report_type}_{timestamp}
        start_date_str = parts[2]  # ä¾‹å¦‚: 20250801
        end_date_str = parts[3]    # ä¾‹å¦‚: 20250831
        report_type = parts[4]     # ä¾‹å¦‚: bndbg
        # timestamp å¯èƒ½åŒ…å«ä¸‹åˆ’çº¿ï¼Œæ‰€ä»¥å–å‰©ä½™éƒ¨åˆ†
        timestamp = '_'.join(parts[5:]) if len(parts) > 5 else ''
        
        file_info = {
            'start_date_str': start_date_str,
            'end_date_str': end_date_str,
            'report_type': report_type,
            'original_timestamp': timestamp
        }
        
        print(f"ğŸ“‹ è§£ææ–‡ä»¶åä¿¡æ¯:")
        print(f"   å¼€å§‹æ—¥æœŸ: {start_date_str}")
        print(f"   ç»“æŸæ—¥æœŸ: {end_date_str}")
        print(f"   æŠ¥å‘Šç±»å‹: {report_type}")
        
        return latest_file, file_info
    else:
        print(f"âš ï¸ æ— æ³•è§£ææ–‡ä»¶åæ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å‘½å")
        return latest_file, None


def pivot_to_wide_format(df_long):
    """
    å°†é•¿æ ¼å¼æ•°æ®è½¬æ¢ä¸ºå®½æ ¼å¼ï¼Œå¹¶æ·»åŠ "æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§"åˆ—
    
    Args:
        df_long (pd.DataFrame): é•¿æ ¼å¼æ•°æ®
    
    Returns:
        pd.DataFrame: å®½æ ¼å¼æ•°æ®
    """
    print("\næ­£åœ¨è¿›è¡Œæ•°æ®é€è§†æ“ä½œ...")
    
    # å…ˆå¯¹æ•°æ®è¿›è¡Œå»é‡
    print("æ­£åœ¨å»é™¤é‡å¤æ•°æ®...")
    df_long_dedup = df_long.drop_duplicates(
        subset=['å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ', 'é¡¹ç›®åç§°'], 
        keep='first'
    )
    print(f"å»é‡å‰: {len(df_long)} è¡Œï¼Œå»é‡å: {len(df_long_dedup)} è¡Œ")
    
    # åˆ›å»ºé‡‘é¢é€è§†è¡¨
    df_pivot = df_long_dedup.pivot_table(
        index=['è¯åˆ¸ä»£ç ', 'å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ', 'PDFé“¾æ¥'], 
        columns='é¡¹ç›®åç§°',                           
        values='é‡‘é¢',                                
        aggfunc='first'                               
    ).reset_index()
    
    print("æ•°æ®é€è§†å®Œæˆï¼")
    
    # åˆ›å»º"æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§"åˆ—
    # æ£€æŸ¥ä¸‰ä¸ªé¡¹ç›®ï¼ˆå­˜è´§ã€æ— å½¢èµ„äº§ã€å¼€å‘æ”¯å‡ºï¼‰æ˜¯å¦æœ‰æ•°æ®
    item_cols = ['å­˜è´§', 'æ— å½¢èµ„äº§', 'å¼€å‘æ”¯å‡º']
    has_data_col = []
    
    for idx, row in df_pivot.iterrows():
        has_data = 0
        for col in item_cols:
            if col in df_pivot.columns:
                value = row[col]
                # æ£€æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯N/Aã€ç©ºå€¼ã€-ç­‰ï¼‰
                if pd.notna(value) and str(value) not in ['N/A', 'ç©ºå€¼', '-', 'nan', 'None']:
                    # å°è¯•æå–æ•°å­—
                    value_str = str(value).replace(',', '').replace(' ', '')
                    if re.search(r'\d', value_str):
                        has_data = 1
                        break
        has_data_col.append(has_data)
    
    df_pivot['æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§'] = has_data_col
    
    # è°ƒæ•´åˆ—é¡ºåºï¼šåŸºæœ¬ä¿¡æ¯ -> é‡‘é¢åˆ— -> æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§ -> PDFé“¾æ¥
    base_cols = ['è¯åˆ¸ä»£ç ', 'å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ']
    amount_cols = [col for col in item_cols if col in df_pivot.columns]
    other_cols = ['æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§', 'PDFé“¾æ¥']
    
    final_columns = base_cols + amount_cols + other_cols
    # åªä¿ç•™å­˜åœ¨çš„åˆ—
    final_columns = [col for col in final_columns if col in df_pivot.columns]
    
    df_final = df_pivot[final_columns]
    
    return df_final


def main():
    """
    ä¸»å‡½æ•° - ä»CSVè¯»å–PDFé“¾æ¥å¹¶æå–æ•°æ®
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°å†³å®šæ˜¯å¦ä¸‹è½½PDF
    if args.no_download:
        download_pdf = False
        print("\nâœ… å·²é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è®¾ç½®ï¼šä»…ç”ŸæˆExcelæ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œä¸ä¸‹è½½PDFï¼‰")
    elif args.download_pdf:
        download_pdf = True
        print("\nâœ… å·²é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è®¾ç½®ï¼šä¸‹è½½PDFå¹¶ç”ŸæˆExcelï¼ˆå®Œæ•´æ¨¡å¼ï¼‰")
    else:
        # è¯¢é—®æ˜¯å¦ä¸‹è½½PDF
        print("\n" + "="*60)
        print("æ˜¯å¦ä¸‹è½½PDFæ–‡ä»¶åˆ°æœ¬åœ°ï¼Ÿ")
        print("y - ä¸‹è½½PDFå¹¶ç”ŸæˆExcelï¼ˆå®Œæ•´æ¨¡å¼ï¼‰")
        print("n - ä»…ç”ŸæˆExcelæ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œä¸ä¸‹è½½PDFï¼‰")
        print("="*60)
        
        while True:
            choice = input("è¯·è¾“å…¥é€‰æ‹© (y/n): ").strip().lower()
            if choice == 'y':
                download_pdf = True
                print("âœ… å·²é€‰æ‹©ï¼šä¸‹è½½PDFå¹¶ç”ŸæˆExcelï¼ˆå®Œæ•´æ¨¡å¼ï¼‰")
                break
            elif choice == 'n':
                download_pdf = False
                print("âœ… å·²é€‰æ‹©ï¼šä»…ç”ŸæˆExcelæ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ y æˆ– n")
    
    print(f"\nğŸ“ PDFä¸‹è½½æ¨¡å¼: {'å¼€å¯' if download_pdf else 'å…³é—­'}")
    if not download_pdf:
        print("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šä»…è§£æPDFå†…å®¹ï¼Œä¸ä¿å­˜åˆ°æœ¬åœ°")
    else:
        print("ğŸ’¾ å®Œæ•´æ¨¡å¼ï¼šä¸‹è½½å¹¶ä¿å­˜PDFæ–‡ä»¶åˆ°æœ¬åœ°")
    
    # æŸ¥æ‰¾CSVæ–‡ä»¶
    csv_file, file_info = find_csv_file(args.csv_file)
    if not csv_file:
        return
    
    # è¯»å–CSVæ–‡ä»¶
    try:
        print(f"\nğŸ“– æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {csv_file}")
        df_csv = pd.read_csv(csv_file, dtype=str)
        print(f"âœ… æˆåŠŸè¯»å– {len(df_csv)} æ¡è®°å½•")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        required_cols = ['PDFé“¾æ¥']
        missing_cols = [col for col in required_cols if col not in df_csv.columns]
        if missing_cols:
            print(f"âŒ CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
            return
        
        # æ˜¾ç¤ºåˆ—å
        print(f"ğŸ“‹ CSVæ–‡ä»¶åŒ…å«çš„åˆ—: {', '.join(df_csv.columns.tolist())}")
        
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # åˆå§‹åŒ–
    session = requests.Session()
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Accept": "application/pdf, application/json, text/plain, */*",
        "Referer": "http://www.cninfo.com.cn/new/commonUrl?url=disclosure/list/notice",
    }
    
    folder_path = os.path.join(os.getcwd(), "FinancialReports_Collection")
    all_results_for_excel = []
    start_time = time.time()
    
    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(df_csv)} ä¸ªPDFé“¾æ¥...")
    print("="*60)
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_row = {
            executor.submit(process_pdf_link, row.to_dict(), session, headers, folder_path, download_pdf): idx 
            for idx, row in df_csv.iterrows()
        }
        
        completed = 0
        for future in as_completed(future_to_row):
            completed += 1
            try:
                extracted_data = future.result()
                if extracted_data:
                    all_results_for_excel.extend(extracted_data)
                print(f"ğŸ“Š è¿›åº¦: {completed}/{len(df_csv)} ({completed/len(df_csv)*100:.1f}%)")
            except Exception as exc:
                print(f'âŒ ä¸€ä¸ªä»»åŠ¡åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {exc}')
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ¯ å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"  ğŸ“Š æ€»è®°å½•æ•°: {len(df_csv)}")
    print(f"  âœ… æˆåŠŸæå–æ•°æ®: {len([r for r in all_results_for_excel if r.get('é‡‘é¢') != 'N/A'])}")
    
    # ç”Ÿæˆæœ€ç»ˆçš„ExcelæŠ¥å‘Š
    print("\n===== æ­£åœ¨ç”ŸæˆExcelæŠ¥å‘Š... =====")
    if all_results_for_excel:
        # ç”Ÿæˆé•¿æ ¼å¼æŠ¥å‘Š
        df_long = pd.DataFrame(all_results_for_excel)
        df_long = df_long[['è¯åˆ¸ä»£ç ', 'å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ', 'é¡¹ç›®åç§°', 'é‡‘é¢', 'æ˜¯å¦åŒ…å«æ•°æ®èµ„äº§', 'PDFé“¾æ¥']]
        
        # æœ€ç»ˆå»é‡å¤„ç†
        print("æ­£åœ¨è¿›è¡Œæœ€ç»ˆæ•°æ®å»é‡...")
        original_count = len(df_long)
        df_long = df_long.drop_duplicates(subset=['å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'é¡¹ç›®åç§°'], keep='first')
        final_count = len(df_long)
        print(f"å»é‡å‰: {original_count} è¡Œï¼Œå»é‡å: {final_count} è¡Œï¼Œå»é™¤äº† {original_count - final_count} è¡Œé‡å¤æ•°æ®")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        # ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºtimestamp
        output_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if file_info:
            # ä»CSVæ–‡ä»¶åä¸­æå–çš„ä¿¡æ¯
            start_date_str = file_info['start_date_str']
            end_date_str = file_info['end_date_str']
            report_type = file_info['report_type']
            
            # æ„å»ºæ–‡ä»¶åï¼šlong_output_{start_date}_{end_date}_{report_type}_{timestamp}.xlsx
            long_output_filename = f'long_output_{start_date_str}_{end_date_str}_{report_type}_{output_timestamp}.xlsx'
            wide_output_filename = f'wide_output_{start_date_str}_{end_date_str}_{report_type}_{output_timestamp}.xlsx'
        else:
            # å¦‚æœæ— æ³•è§£ææ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤å‘½å
            long_output_filename = f'long_output_{output_timestamp}.xlsx'
            wide_output_filename = f'wide_output_{output_timestamp}.xlsx'
        
        # ç”Ÿæˆé•¿æ ¼å¼Excel
        if os.path.exists(long_output_filename):
            os.remove(long_output_filename)
        df_long.to_excel(long_output_filename, index=False)
        print(f"ğŸ‰ é•¿æ ¼å¼æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ï¼å·²ä¿å­˜ä¸º ./{long_output_filename}")
        
        # ç”Ÿæˆå®½æ ¼å¼æŠ¥å‘Š
        print("\næ­£åœ¨ç”Ÿæˆå®½æ ¼å¼æŠ¥å‘Š...")
        df_wide = pivot_to_wide_format(df_long)
        
        if os.path.exists(wide_output_filename):
            os.remove(wide_output_filename)
        
        df_wide.to_excel(wide_output_filename, index=False, freeze_panes=(1, 0))
        print(f"ğŸ‰ å®½æ ¼å¼æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ï¼å·²ä¿å­˜ä¸º ./{wide_output_filename}")
        
        print("\nğŸ“Š å®½æ ¼å¼æŠ¥å‘Šé¢„è§ˆ:")
        print(df_wide.head(10))
    else:
        print("âŒ æœªæå–åˆ°ä»»ä½•æ•°æ®ï¼Œä¸ç”ŸæˆExcelæ–‡ä»¶ã€‚")
        
    end_time = time.time()
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {(end_time - start_time):.2f} ç§’")
    print("âœ… ç¨‹åºæ‰§è¡Œå®Œæ¯•")


if __name__ == "__main__":
    print("=" * 60)
    print("æŠ¥å‘Šä¿¡æ¯æ”¶é›†å™¨ - æ•°æ®èµ„æºæå–å·¥å…·")
    print("=" * 60)
    print("åŠŸèƒ½ï¼šä»CSVæ–‡ä»¶è¯»å–PDFé“¾æ¥å¹¶æå–æ•°æ®èµ„æºä¿¡æ¯")
    print("è¾“å‡ºï¼šç”Ÿæˆé•¿æ ¼å¼å’Œå®½æ ¼å¼çš„ExcelæŠ¥å‘Š")
    print("=" * 60)
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print("  python report_info_collection.py                              # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„CSVæ–‡ä»¶ï¼Œä¼šè¯¢é—®æ˜¯å¦ä¸‹è½½PDF")
    print("  python report_info_collection.py --csv-file file.csv          # æŒ‡å®šCSVæ–‡ä»¶ï¼Œä¼šè¯¢é—®æ˜¯å¦ä¸‹è½½PDF")
    print("  python report_info_collection.py --no-download                 # ä¸ä¸‹è½½PDFï¼Œä»…è§£ææ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
    print("  python report_info_collection.py --download-pdf                # ä¸‹è½½PDFåˆ°æœ¬åœ°ï¼ˆå®Œæ•´æ¨¡å¼ï¼‰")
    print("  python report_info_collection.py --csv-file file.csv --no-download  # æŒ‡å®šCSVæ–‡ä»¶ä¸”ä¸ä¸‹è½½PDF")
    print("=" * 60)
    
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nç¨‹åºæ‰§è¡Œå®Œæ¯•")

