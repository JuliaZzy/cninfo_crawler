#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è´¢åŠ¡æ•°æ®çˆ¬è™« - ä»å·¨æ½®èµ„è®¯ç½‘çˆ¬å–ä¸Šå¸‚å…¬å¸è´¢åŠ¡æŠ¥å‘Šä¸­çš„"æ•°æ®èµ„æº"ä¿¡æ¯ (å¢å¼ºç‰ˆ)
åŠŸèƒ½ï¼š
1. çˆ¬å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„è´¢åŠ¡æŠ¥å‘ŠPDF
2. è§£æPDFä¸­çš„"æ•°æ®èµ„æº"ç›¸å…³æ•°æ®
3. ç”Ÿæˆé•¿æ ¼å¼å’Œå®½æ ¼å¼çš„ExcelæŠ¥å‘Š
4. æ”¯æŒå¤šä¸ªäº¤æ˜“æ‰€ï¼Œä¸“æ³¨2025å¹´åŠå¹´æŠ¥
5. ä½¿ç”¨å¤šä¸ªAPIæ¥å£æé«˜æ•°æ®å®Œæ•´æ€§
6. æ™ºèƒ½å»é‡å’Œæ•°æ®ç»Ÿè®¡

å¢å¼ºç‰¹æ€§ï¼š
- æ”¯æŒ5ä¸ªäº¤æ˜“æ‰€ï¼šä¸Šäº¤æ‰€ã€æ·±äº¤æ‰€ã€åŒ—äº¤æ‰€ã€æ–°ä¸‰æ¿ã€ç§‘åˆ›æ¿
- ä¸“æ³¨2025å¹´åŠå¹´æŠ¥æ•°æ®
- ä½¿ç”¨3ä¸ªAPIæ¥å£ç¡®ä¿æ•°æ®å®Œæ•´æ€§
- æ™ºèƒ½å»é‡é¿å…é‡å¤æ•°æ®
- è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º

ä½œè€…ï¼šåŸºäºjc_local_crawler.ipynbè½¬æ¢å¹¶å¢å¼º
æ—¥æœŸï¼š2025å¹´
"""

import os
import re
import requests
import pandas as pd
import pdfplumber
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import sys
from datetime import datetime, timedelta
import warnings
import logging

# æŠ‘åˆ¶pdfplumberçš„è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=UserWarning, module="pdfplumber")
logging.getLogger("pdfplumber").setLevel(logging.ERROR)


def extract_data_by_category(pdf_content, pdf_url):
    """
    é€šè¿‡è§£æPDFä¸­çš„è¡¨æ ¼ç»“æ„æ¥æå–æ•°æ®ï¼Œèƒ½å¤Ÿç²¾ç¡®åŒºåˆ†åˆ—ï¼Œé¿å…è¯¯æŠ“ã€‚
    ä¼˜åŒ–ï¼šæ·»åŠ å»é‡é€»è¾‘ï¼Œé¿å…é‡å¤æå–ç›¸åŒæ•°æ®ã€‚
    æ–°å¢ï¼šæ™ºèƒ½æŸ¥æ‰¾æ•°å­—ä½ç½®ï¼Œæ·»åŠ äººå·¥æ£€æµ‹æ ‡è®°ã€‚
    
    Args:
        pdf_content (bytes): PDFæ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
        pdf_url (str): PDFæ–‡ä»¶çš„URLï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        list: åŒ…å«æå–æ•°æ®çš„å­—å…¸åˆ—è¡¨
    """
    found_items = []
    parent_categories = ["å­˜è´§", "æ— å½¢èµ„äº§", "å¼€å‘æ”¯å‡º"]
    # ç”¨äºå»é‡çš„é›†åˆï¼Œè®°å½•å·²ç»æ‰¾åˆ°çš„ç±»åˆ«
    found_categories = set()
    
    def find_first_number_in_row(row, start_col=1):
        """
        åœ¨è¡Œçš„æŒ‡å®šåˆ—å¼€å§‹ä½ç½®æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ•°å­—
        
        Args:
            row (list): è¡¨æ ¼è¡Œæ•°æ®
            start_col (int): å¼€å§‹æŸ¥æ‰¾çš„åˆ—ç´¢å¼•
            
        Returns:
            tuple: (æ‰¾åˆ°çš„æ•°å­—, æ˜¯å¦æ£€æµ‹åˆ°æ•°å­—)
        """
        has_number = False
        found_value = "ç©ºå€¼"
        
        for i in range(start_col, len(row)):
            cell_value = row[i]
            if cell_value and isinstance(cell_value, str):
                # æ¸…ç†å•å…ƒæ ¼å†…å®¹ï¼Œå»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
                cleaned_value = cell_value.strip().replace(' ', '')
                
                # æ›´å®½æ¾çš„æ•°å­—åŒ¹é…æ¨¡å¼ï¼ŒåŒ…æ‹¬å„ç§æ ¼å¼
                number_patterns = [
                    r'((?:\d{1,3},)*\d{1,3}\.\d{2})',  # æ ‡å‡†æ ¼å¼ï¼š1,234.56
                    r'((?:\d{1,3},)*\d+)',              # æ•´æ•°æ ¼å¼ï¼š1,234
                    r'(\d+\.\d{2})',                    # ç®€å•å°æ•°ï¼š123.45
                    r'(\d+)',                           # çº¯æ•°å­—ï¼š123
                    r'(-)',                             # è´Ÿå·æˆ–ç©ºå€¼æ ‡è®°
                ]
                
                for pattern in number_patterns:
                    match = re.search(pattern, cleaned_value)
                    if match:
                        found_value = match.group(1)
                        has_number = True
                        break
                
                if has_number:
                    break
        
        return found_value, has_number
    
    try:
        # ä¸´æ—¶æŠ‘åˆ¶pdfplumberçš„è­¦å‘Š
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            with pdfplumber.open(BytesIO(pdf_content)) as pdf:
                for page in pdf.pages:
                    # å°è¯•æå–é¡µé¢ä¸Šçš„æ‰€æœ‰è¡¨æ ¼
                    tables = page.extract_tables()
                    if not tables:
                        continue

                    for table in tables:
                        last_parent_item = None
                        # éå†è¡¨æ ¼çš„æ¯ä¸€è¡Œ
                        for row in table:
                            if not row or not row[0]:  # è·³è¿‡ç©ºè¡Œæˆ–ç¬¬ä¸€åˆ—ä¸ºç©ºçš„è¡Œ
                                continue
                            
                            # æ¸…ç†ç¬¬ä¸€åˆ—çš„æ–‡æœ¬ï¼Œå»é™¤æ¢è¡Œç¬¦
                            first_col_text = row[0].replace('\n', '')

                            # æ­¥éª¤1: æ£€æŸ¥æ˜¯å¦ä¸ºçˆ¶é¡¹
                            is_parent = False
                            for cat in parent_categories:
                                if cat in first_col_text:
                                    last_parent_item = cat
                                    is_parent = True
                                    break
                            if is_parent:
                                continue # å¦‚æœæ˜¯çˆ¶é¡¹è¡Œï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€è¡Œ

                            # æ­¥éª¤2: æ£€æŸ¥æ˜¯å¦ä¸ºå­é¡¹ï¼Œå¹¶ä¸”æˆ‘ä»¬å·²ç»æ‰¾åˆ°äº†å®ƒçš„çˆ¶é¡¹
                            if last_parent_item and "æ•°æ®èµ„æº" in first_col_text:
                                # å»é‡æ£€æŸ¥ï¼šå¦‚æœè¿™ä¸ªç±»åˆ«å·²ç»æ‰¾åˆ°è¿‡ï¼Œè·³è¿‡
                                if last_parent_item in found_categories:
                                    continue
                                    
                                # æ­¥éª¤3: æ™ºèƒ½æŸ¥æ‰¾æ•°å­—ä½ç½®
                                found_value, has_number = find_first_number_in_row(row, start_col=1)
                                
                                if has_number:
                                    print(f"    âœ… {last_parent_item}æ•°æ®èµ„æº: {found_value}")
                                else:
                                    print(f"    âš ï¸ {last_parent_item}æ•°æ®èµ„æº: æœªæ£€æµ‹åˆ°æ•°å­—")

                                found_items.append({
                                    "category": last_parent_item,
                                    "value": found_value,
                                    "manual_check": 1 if has_number else 0  # æ–°å¢ï¼šäººå·¥æ£€æµ‹æ ‡è®°
                                })
                                # è®°å½•å·²æ‰¾åˆ°çš„ç±»åˆ«ï¼Œé¿å…é‡å¤
                                found_categories.add(last_parent_item)
                                # é‡ç½®çˆ¶é¡¹ï¼Œé¿å…ä¸‹ä¸€è¡Œçš„å…¶ä»–"å…¶ä¸­"é¡¹è¢«é”™è¯¯å½’ç±»
                                last_parent_item = None

    except Exception as e:
        print(f"    âŒ è§£æPDFè¡¨æ ¼æ—¶å‡ºé”™: {e}")
        return [{"category": "è¡¨æ ¼è§£æå¤±è´¥", "value": str(e), "manual_check": 0}]
        
    if not found_items:
        print(f"    âš ï¸ åœ¨æ­¤PDFçš„ä»»ä½•è¡¨æ ¼ä¸­æœªæ‰¾åˆ°'æ•°æ®èµ„æº'ç›¸å…³æ¡ç›®ã€‚")
        
    return found_items


def process_announcement(announcement_info, session, headers, folder_path, download_pdf=True):
    """
    ä¸‹è½½å•ä¸ªå…¬å‘ŠPDFï¼Œåœ¨å†…å­˜ä¸­è¿›è¡Œè§£æï¼Œä¿å­˜æ–‡ä»¶ï¼Œå¹¶è¿”å›è§£æç»“æœã€‚
    
    Args:
        announcement_info (dict): å…¬å‘Šä¿¡æ¯
        session (requests.Session): è¯·æ±‚ä¼šè¯
        headers (dict): è¯·æ±‚å¤´
        folder_path (str): ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„
        download_pdf (bool): æ˜¯å¦ä¸‹è½½PDFæ–‡ä»¶åˆ°æœ¬åœ°
    
    Returns:
        list: è§£æç»“æœåˆ—è¡¨
    """
    file_url = 'https://static.cninfo.com.cn/' + announcement_info['adjunctUrl']
    sec_name = announcement_info.get('secName', 'æœªçŸ¥å…¬å¸')
    sec_code = announcement_info.get('secCode', 'æœªçŸ¥ä»£ç ')
    announcement_title = announcement_info.get('announcementTitle', 'æœªçŸ¥æŠ¥å‘Š')
    
    # å¤„ç†è¯åˆ¸ä»£ç ï¼šç¡®ä¿6ä½æ ¼å¼å¹¶æ·»åŠ äº¤æ˜“æ‰€åç¼€
    if sec_code and sec_code != 'æœªçŸ¥ä»£ç ':
        sec_code_str = str(sec_code)
        
        # å¦‚æœæ˜¯æ•°å­—ï¼Œè¡¥é½å‰å¯¼é›¶åˆ°6ä½
        if sec_code_str.isdigit():
            sec_code_str = sec_code_str.zfill(6)  # è¡¥é½åˆ°6ä½ï¼Œå¦‚ 1 -> 000001
        
        # æ·»åŠ äº¤æ˜“æ‰€åç¼€
        if sec_code_str.startswith('60') or sec_code_str.startswith('68'):
            sec_code = sec_code_str + '.SH'  # ä¸Šäº¤æ‰€
        elif sec_code_str.startswith('00') or sec_code_str.startswith('30'):
            sec_code = sec_code_str + '.SZ'  # æ·±äº¤æ‰€
        elif sec_code_str.startswith('83') or sec_code_str.startswith('87') or sec_code_str.startswith('92'):
            sec_code = sec_code_str + '.BJ'  # åŒ—äº¤æ‰€
        else:
            sec_code = sec_code_str  # ä¿æŒåŸæ ·
    
    # å¤„ç†æ—¶é—´æˆ³
    raw_time = announcement_info.get('announcementTime')
    if isinstance(raw_time, int):
        # å¦‚æœæ˜¯æ—¶é—´æˆ³ (é€šå¸¸æ˜¯æ¯«ç§’), å°†å…¶è½¬æ¢ä¸ºæ—¥æœŸå­—ç¬¦ä¸²
        date_str = datetime.fromtimestamp(raw_time / 1000).strftime('%Y-%m-%d')
    elif isinstance(raw_time, str):
        # å¦‚æœæ˜¯å­—ç¬¦ä¸², æŒ‰åŸè®¡åˆ’åˆ‡å‰²
        date_str = raw_time.split(' ')[0]
    else:
        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹æˆ–None, ä½¿ç”¨å½“å¤©æ—¥æœŸä½œä¸ºå¤‡ç”¨
        date_str = datetime.now().strftime('%Y-%m-%d')
    
    # ä¸¥æ ¼è¿‡æ»¤ï¼šåªå¤„ç†2025å¹´çš„æŠ¥å‘Šï¼Œè·³è¿‡æ‰€æœ‰å…¶ä»–å¹´ä»½
    if not date_str.startswith('2025'):
        print(f"  âŒ è·³è¿‡é2025å¹´æŠ¥å‘Š: {announcement_title} ({date_str})")
        return []
    
    # é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿æ˜¯2025å¹´çš„æ•°æ®
    try:
        report_year = int(date_str.split('-')[0])
        if report_year != 2025:
            print(f"  âŒ è·³è¿‡é2025å¹´æŠ¥å‘Š: {announcement_title} (å¹´ä»½: {report_year})")
            return []
    except (ValueError, IndexError):
        print(f"  âŒ è·³è¿‡æ—¥æœŸæ ¼å¼å¼‚å¸¸çš„æŠ¥å‘Š: {announcement_title} ({date_str})")
        return []
    
    # è¿‡æ»¤ï¼šæ’é™¤åŒ…å«"æ‘˜è¦"çš„æŠ¥å‘Š
    if 'æ‘˜è¦' in announcement_title:
        print(f"  è·³è¿‡æ‘˜è¦æŠ¥å‘Š: {announcement_title}")
        return []
    
    # è¿‡æ»¤ï¼šä¼˜å…ˆå¤„ç†æ›´æ­£ç‰ˆæœ¬ï¼Œå¦‚æœæ²¡æœ‰æ›´æ­£ç‰ˆæœ¬åˆ™å¤„ç†åŸå§‹ç‰ˆæœ¬
    if 'æ›´æ­£' in announcement_title or 'ä¿®è®¢' in announcement_title:
        print(f"  å¤„ç†æ›´æ­£ç‰ˆæœ¬: {announcement_title}")
        # ç»§ç»­å¤„ç†æ›´æ­£ç‰ˆæœ¬
    else:
        print(f"  å¤„ç†åŸå§‹ç‰ˆæœ¬: {announcement_title}")
        # ç»§ç»­å¤„ç†åŸå§‹ç‰ˆæœ¬

    # æ¸…ç†å¹¶æ„é€ æ–‡ä»¶å
    report_name_base = f"{sec_name}ï¼š{announcement_title}_[{date_str}]"
    file_name = re.sub(r'[\\/:*?"<>|]', '_', report_name_base) + ".pdf"
    file_path = os.path.join(folder_path, file_name)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆä»…åœ¨ä¸‹è½½PDFæ¨¡å¼ä¸‹æ£€æŸ¥ï¼‰
    if download_pdf and os.path.exists(file_path):
        print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {file_name}")
        return [] # å·²å­˜åœ¨åˆ™ä¸é‡å¤å¤„ç†

    try:
        print(f"  æ­£åœ¨ä¸‹è½½: {file_name}")
        response = session.get(file_url, headers=headers, timeout=(15, 45))
        response.raise_for_status()
        
        # éªŒè¯æ˜¯å¦ä¸ºPDF
        if 'application/pdf' not in response.headers.get('Content-Type', ''):
            print(f"  è­¦å‘Š: {file_name} ä¸æ˜¯PDFæ–‡ä»¶ã€‚")
            return []

        pdf_content = response.content

        # åœ¨å†…å­˜ä¸­è§£æPDFå†…å®¹
        extracted_data = extract_data_by_category(pdf_content, file_url)
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šæ˜¯å¦ä¿å­˜PDFæ–‡ä»¶åˆ°æœ¬åœ°
        if download_pdf:
            with open(file_path, 'wb') as f:
                f.write(pdf_content)
            print(f"  âœ… PDFå·²ä¿å­˜: {file_name}")
        else:
            print(f"  ğŸ“Š ä»…è§£ææ•°æ®ï¼Œæœªä¿å­˜PDF: {file_name}")
        
        # å°†æŠ¥å‘Šè‡ªèº«ä¿¡æ¯æ·»åŠ åˆ°æå–ç»“æœä¸­ï¼Œæ–¹ä¾¿åç»­æ±‡æ€»
        results_for_excel = []
        if extracted_data:
            for item in extracted_data:
                results_for_excel.append({
                    "è¯åˆ¸ä»£ç ": sec_code,
                    "å…¬å¸åç§°": sec_name,
                    "æŠ¥å‘Šåç§°": announcement_title,
                    "æŠ¥å‘Šæ—¥æœŸ": date_str,
                    "é¡¹ç›®åç§°": item['category'],
                    "é‡‘é¢": item['value'],
                    "äººå·¥æ£€æµ‹": item.get('manual_check', 0),  # æ–°å¢ï¼šäººå·¥æ£€æµ‹æ ‡è®°
                    "PDFé“¾æ¥": file_url
                })
        else:
            # å³ä½¿æ²¡æ‰¾åˆ°æ•°æ®ï¼Œä¹Ÿè®°å½•ä¸€æ¡ï¼Œæ–¹ä¾¿è¿½æº¯
            results_for_excel.append({
                "è¯åˆ¸ä»£ç ": sec_code,
                "å…¬å¸åç§°": sec_name,
                "æŠ¥å‘Šåç§°": announcement_title,
                "æŠ¥å‘Šæ—¥æœŸ": date_str,
                "é¡¹ç›®åç§°": "æœªæ‰¾åˆ°",
                "é‡‘é¢": "N/A",
                "äººå·¥æ£€æµ‹": 0,  # æœªæ‰¾åˆ°æ•°æ®æ—¶æ ‡è®°ä¸º0
                "PDFé“¾æ¥": file_url
            })
            
        return results_for_excel

    except requests.exceptions.RequestException as e:
        print(f"  ä¸‹è½½æˆ–å¤„ç† {file_name} å¤±è´¥: {e}")
        return []


def get_announcements_multi_api(session, headers, exchange, date_str, report_categories, api_urls):
    """
    ä½¿ç”¨å¤šä¸ªAPIæ¥å£è·å–å…¬å‘Šæ•°æ®ï¼Œæé«˜æ•°æ®å®Œæ•´æ€§
    
    Args:
        session: è¯·æ±‚ä¼šè¯
        headers: è¯·æ±‚å¤´
        exchange: äº¤æ˜“æ‰€ä¿¡æ¯
        date_str: æ—¥æœŸå­—ç¬¦ä¸²
        report_categories: æŠ¥å‘Šç±»åˆ«åˆ—è¡¨
        api_urls: APIæ¥å£åˆ—è¡¨
    
    Returns:
        list: å…¬å‘Šåˆ—è¡¨
    """
    all_announcements = []
    seen_announcements = set()  # ç”¨äºå»é‡
    
    for api_url in api_urls:
        print(f"  ğŸŒ å°è¯•API: {api_url}")
        for report_category in report_categories:
            print(f"    ğŸ“‹ æŠ¥å‘Šç±»å‹: {report_category}")
            page_num = 1
            while True:
                try:
                    # è¯·æ±‚å‚æ•°
                    post_data = {
                        "pageNum": str(page_num), 
                        "pageSize": "30", 
                        "column": exchange["column"],
                        "tabName": "fulltext", 
                        "plate": "", 
                        "stock": "", 
                        "searchkey": "",
                        "secid": "", 
                        "category": report_category, 
                        "trade": "",
                        "seDate": f"{date_str}~{date_str}", 
                        "sortName": "", 
                        "sortType": "",
                        "isHLtitle": "true"
                    }
                    
                    response = session.post(api_url, headers=headers, data=post_data, timeout=20)
                    response.raise_for_status()
                    data = response.json()
                    
                    # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
                    if isinstance(data, list):
                        announcements = data
                    elif isinstance(data, dict):
                        announcements = data.get('announcements', [])
                    else:
                        announcements = []
                    
                    if not announcements:
                        if page_num == 1:
                            print(f"    âŒ ç¬¬1é¡µæ— æ•°æ®ï¼Œè·³è¿‡æ­¤API")
                        break
                    
                    print(f"    âœ… ç¬¬{page_num}é¡µè·å–åˆ° {len(announcements)} ä¸ªå…¬å‘Š")
                    
                    # å»é‡å¤„ç† + 2025å¹´è¿‡æ»¤
                    for ann in announcements:
                        # å…ˆæ£€æŸ¥æ˜¯å¦ä¸º2025å¹´çš„æŠ¥å‘Š
                        announcement_time = ann.get('announcementTime', '')
                        if announcement_time:
                            try:
                                if isinstance(announcement_time, int):
                                    # æ—¶é—´æˆ³æ ¼å¼
                                    ann_date = datetime.fromtimestamp(announcement_time / 1000)
                                elif isinstance(announcement_time, str):
                                    # å­—ç¬¦ä¸²æ ¼å¼
                                    ann_date = datetime.strptime(announcement_time.split(' ')[0], '%Y-%m-%d')
                                else:
                                    continue
                                
                                # åªä¿ç•™2025å¹´çš„æŠ¥å‘Š
                                if ann_date.year != 2025:
                                    continue
                                    
                            except (ValueError, TypeError):
                                # æ—¥æœŸè§£æå¤±è´¥ï¼Œè·³è¿‡
                                continue
                        
                        # ä½¿ç”¨å¤šä¸ªå­—æ®µç»„åˆä½œä¸ºå”¯ä¸€æ ‡è¯†
                        unique_key = (
                            ann.get('secCode', ''),
                            ann.get('announcementTitle', ''),
                            ann.get('announcementTime', ''),
                            ann.get('adjunctUrl', '')
                        )
                        
                        if unique_key not in seen_announcements:
                            seen_announcements.add(unique_key)
                            all_announcements.append(ann)
                    
                    page_num += 1
                    time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    
                except Exception as e:
                    print(f"  âš ï¸ API {api_url} è·å–æ•°æ®å¤±è´¥: {e}")
                    # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªAPIï¼Œè€Œä¸æ˜¯ç›´æ¥break
                    continue
    
    print(f"  ğŸ“Š APIè°ƒç”¨å®Œæˆï¼Œå…±è·å–åˆ° {len(all_announcements)} ä¸ªæœ‰æ•ˆå…¬å‘Š")
    return all_announcements


def pivot_financial_data(source_filename='æ•°æ®èµ„æºæå–ç»“æœ.xlsx', 
                         output_filename='æœ€ç»ˆå®½æ ¼å¼æŠ¥å‘Š.xlsx'):
    """
    è¯»å–çˆ¬è™«ç”Ÿæˆçš„é•¿æ ¼å¼Excelæ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå®½æ ¼å¼ã€‚
    æ­¤ç‰ˆæœ¬å°†"PDFé“¾æ¥"åˆ—æ”¾åœ¨æœ€åã€‚
    
    Args:
        source_filename (str): æºExcelæ–‡ä»¶å
        output_filename (str): è¾“å‡ºExcelæ–‡ä»¶å
    """
    try:
        print(f"æ­£åœ¨è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶: {source_filename}")
        df_long = pd.read_excel(source_filename)
        print("åŸå§‹æ•°æ®è¯»å–æˆåŠŸï¼")
        
        print("\nåŸå§‹æ•°æ®é¢„è§ˆ:")
        print(df_long.head())

    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°åŸå§‹æ•°æ®æ–‡ä»¶ '{source_filename}'ã€‚")
        print("è¯·å…ˆç¡®ä¿çˆ¬è™«å·²æˆåŠŸè¿è¡Œï¼Œå¹¶ç”Ÿæˆäº†æ­¤æ–‡ä»¶ã€‚")
        return
    except Exception as e:
        print(f"è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return

    print("\næ­£åœ¨è¿›è¡Œæ•°æ®é€è§†æ“ä½œ...")
    
    # å…ˆå¯¹æ•°æ®è¿›è¡Œå»é‡ï¼Œé¿å…é‡å¤è¡Œ
    print("æ­£åœ¨å»é™¤é‡å¤æ•°æ®...")
    df_long_dedup = df_long.drop_duplicates(subset=['å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ', 'é¡¹ç›®åç§°'], keep='first')
    print(f"å»é‡å‰: {len(df_long)} è¡Œï¼Œå»é‡å: {len(df_long_dedup)} è¡Œ")
    
    # ä¸ºäººå·¥æ£€æµ‹åˆ—åˆ›å»ºé€è§†è¡¨
    df_pivot_check = df_long_dedup.pivot_table(
        index=['è¯åˆ¸ä»£ç ', 'å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ', 'PDFé“¾æ¥'], 
        columns='é¡¹ç›®åç§°',                           
        values='äººå·¥æ£€æµ‹',                            
        aggfunc='max'  # ä½¿ç”¨maxç¡®ä¿åªè¦æœ‰æ£€æµ‹åˆ°å°±æ ‡è®°ä¸º1
    ).reset_index()
    
    df_pivot = df_long_dedup.pivot_table(
        index=['è¯åˆ¸ä»£ç ', 'å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'æŠ¥å‘Šæ—¥æœŸ', 'PDFé“¾æ¥'], 
        columns='é¡¹ç›®åç§°',                           
        values='é‡‘é¢',                                
        aggfunc='first'                               
    ).reset_index()
    print("æ•°æ®é€è§†å®Œæˆï¼")
    
    if 'æœªæ‰¾åˆ°' in df_pivot.columns:
        df_pivot = df_pivot.drop(columns='æœªæ‰¾åˆ°')
    if 'æœªæ‰¾åˆ°' in df_pivot_check.columns:
        df_pivot_check = df_pivot_check.drop(columns='æœªæ‰¾åˆ°')
    
    final_df = pd.DataFrame()
    final_df['è¯åˆ¸ä»£ç '] = df_pivot['è¯åˆ¸ä»£ç ']
    final_df['å…¬å¸åç§°'] = df_pivot['å…¬å¸åç§°']
    final_df['æŠ¥å‘Šåç§°'] = df_pivot['æŠ¥å‘Šåç§°']
    final_df['æŠ¥å‘Šæ—¥æœŸ'] = df_pivot['æŠ¥å‘Šæ—¥æœŸ']
    final_df['PDFé“¾æ¥'] = df_pivot['PDFé“¾æ¥']

    # æ·»åŠ é‡‘é¢åˆ—
    item_cols = ['æ— å½¢èµ„äº§', 'å¼€å‘æ”¯å‡º', 'å­˜è´§']
    for col in item_cols:
        if col in df_pivot.columns:
            final_df[col] = df_pivot[col]
    
    # æ·»åŠ äººå·¥æ£€æµ‹åˆ—
    for col in item_cols:
        check_col = f"{col}_æ£€æµ‹"
        if col in df_pivot_check.columns:
            final_df[check_col] = df_pivot_check[col]
        else:
            final_df[check_col] = 0  # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ ‡è®°ä¸º0
    
    # è°ƒæ•´åˆ—é¡ºåºï¼Œå°†"PDFé“¾æ¥"ç½®äºæœ«å°¾
    print("\næŒ‰è¦æ±‚è°ƒæ•´åˆ—é¡ºåºï¼Œå°†'PDFé“¾æ¥'ç½®äºæœ«å°¾...")
    
    # 1. è·å–å½“å‰æ‰€æœ‰çš„åˆ—å
    all_columns = final_df.columns.tolist()
    
    # 2. ä»åˆ—è¡¨ä¸­ç§»é™¤ 'PDFé“¾æ¥'
    if 'PDFé“¾æ¥' in all_columns:
        all_columns.remove('PDFé“¾æ¥')
    
    # 3. å°† 'PDFé“¾æ¥' æ·»åŠ åˆ°åˆ—è¡¨çš„æœ«å°¾
    final_ordered_columns = all_columns + ['PDFé“¾æ¥']
    
    # 4. ä½¿ç”¨æ–°çš„åˆ—é¡ºåºæ¥é‡æ–°æ’åˆ—DataFrame
    final_df = final_df[final_ordered_columns]

    print("\næœ€ç»ˆæŠ¥å‘Šé¢„è§ˆ (å·²è°ƒæ•´åˆ—é¡ºåº):")
    print(final_df.head())

    try:
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
        if os.path.exists(output_filename):
            os.remove(output_filename)
            print(f"å·²åˆ é™¤æ—§çš„ {output_filename} æ–‡ä»¶")
            
        print(f"\næ­£åœ¨ä¿å­˜ä¸ºæ–°çš„Excelæ–‡ä»¶: {output_filename}")
        final_df.to_excel(output_filename, index=False, freeze_panes=(1, 0))
        print("ğŸ‰ æœ€ç»ˆæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
    except Exception as e:
        print(f"ä¿å­˜æœ€ç»ˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")


def main():
    """
    ä¸»å‡½æ•° - çˆ¬å–è´¢åŠ¡æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š
    """
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        choice = sys.argv[1].lower()
        if choice in ['y', 'yes', 'true', '1']:
            download_pdf = True
            print("âœ… å‘½ä»¤è¡Œå‚æ•°ï¼šä¸‹è½½PDFå¹¶ç”ŸæˆExcelï¼ˆå®Œæ•´æ¨¡å¼ï¼‰")
        elif choice in ['n', 'no', 'false', '0']:
            download_pdf = False
            print("âœ… å‘½ä»¤è¡Œå‚æ•°ï¼šä»…ç”ŸæˆExcelæ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
        else:
            print("âŒ æ— æ•ˆå‚æ•°ï¼Œä½¿ç”¨äº¤äº’å¼é€‰æ‹©")
            choice = None
    else:
        choice = None
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨äº¤äº’å¼é€‰æ‹©
    if choice is None:
        print("\n" + "="*60)
        print("æ˜¯å¦ä¸‹è½½PDFæ–‡ä»¶ï¼Ÿ")
        print("y - ä¸‹è½½PDFå¹¶ç”ŸæˆExcelï¼ˆå®Œæ•´æ¨¡å¼ï¼Œéœ€è¦16å°æ—¶ï¼‰")
        print("n - ä»…ç”ŸæˆExcelæ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œä¸ä¸‹è½½PDFï¼‰")
        print("="*60)
        
        while True:
            choice = input("è¯·è¾“å…¥é€‰æ‹© (y/n): ").strip().lower()
            if choice == 'y':
                download_pdf = True
                print("âœ… å·²é€‰æ‹©ï¼šä¸‹è½½PDFå¹¶ç”ŸæˆExcelï¼ˆå®Œæ•´æ¨¡å¼ï¼‰")
                break
            elif choice == 'n':
                download_pdf = False
                print("âœ… å·²é€‰æ‹©ï¼šä»…ç”ŸæˆExcelæ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ y æˆ– n")
    
    print(f"\nğŸ“ PDFä¸‹è½½æ¨¡å¼: {'å¼€å¯' if download_pdf else 'å…³é—­'}")
    if not download_pdf:
        print("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šä»…è§£æPDFå†…å®¹ï¼Œä¸ä¿å­˜åˆ°æœ¬åœ°")
    else:
        print("ğŸ’¾ å®Œæ•´æ¨¡å¼ï¼šä¸‹è½½å¹¶ä¿å­˜PDFæ–‡ä»¶åˆ°æœ¬åœ°")
    session = requests.Session()
    api_url = 'http://www.cninfo.com.cn/new/hisAnnouncement/query'

    # è¯·æ±‚å¤´é…ç½®
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Accept": "application/json, text/plain, */*",
        "Referer": "http://www.cninfo.com.cn/new/commonUrl?url=disclosure/list/notice",
        "Content-Type": "application/x-www-form-urlencoded"
    }

    # çˆ¬å–å‚æ•°é…ç½® - ä¸“æ³¨2025å¹´åŠå¹´æŠ¥
    start_date = datetime(2025, 7, 1)  # åŠå¹´æŠ¥é€šå¸¸åœ¨7-8æœˆå‘å¸ƒ
    end_date = datetime(2025, 9, 1)
    
    # åªçˆ¬å–2025å¹´åŠå¹´æŠ¥
    report_categories = [
        "category_bndbg_szsh"  # åŠå¹´æŠ¥
    ]
    
    # ä½¿ç”¨æœ‰æ•ˆçš„APIæ¥å£
    api_urls = [
        'http://www.cninfo.com.cn/new/hisAnnouncement/query'  # ä¸»è¦APIæ¥å£
    ]

    # åˆå§‹åŒ–
    date_list = [(start_date + timedelta(days=i)).strftime("%Y-%m-%d") for i in range((end_date - start_date).days + 1)]
    folder_path = os.path.join(os.getcwd(), "FinancialReports_Final")
    if download_pdf:
        os.makedirs(folder_path, exist_ok=True)
    all_results_for_excel = []
    start_time = time.time()
    
    # å®šä¹‰è¦çˆ¬å–çš„äº¤æ˜“æ‰€åˆ—è¡¨ - å¢å¼ºç‰ˆï¼Œè¦†ç›–æ›´å¤šäº¤æ˜“æ‰€
    exchanges = [
        {"name": "ä¸Šäº¤æ‰€", "column": "sse"},
        {"name": "æ·±äº¤æ‰€", "column": "szse"},
        {"name": "åŒ—äº¤æ‰€", "column": "bj"},
        {"name": "æ–°ä¸‰æ¿", "column": "neeq"},
        {"name": "ç§‘åˆ›æ¿", "column": "star"}
    ]
    
    print(f"\nğŸ¯ ä¸“æ³¨2025å¹´åŠå¹´æŠ¥æ•°æ®çˆ¬å–")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
    print(f"ğŸ¢ äº¤æ˜“æ‰€: {', '.join([ex['name'] for ex in exchanges])}")
    print(f"ğŸ“Š æŠ¥å‘Šç±»å‹: åŠå¹´æŠ¥ (category_bndbg_szsh)")
    print(f"ğŸ” è¿‡æ»¤è§„åˆ™: ä¸¥æ ¼åªå¤„ç†2025å¹´æ•°æ®ï¼Œè·³è¿‡æ‰€æœ‰å…¶ä»–å¹´ä»½")
    if download_pdf:
        print(f"ğŸ’¾ PDFæ–‡ä»¶å°†ä¿å­˜åœ¨: {folder_path}")
    else:
        print("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šä»…è§£æPDFå†…å®¹ï¼Œä¸ä¿å­˜åˆ°æœ¬åœ°")
    print("ğŸ“ˆ åŒæ—¶ç”ŸæˆåŒ…å«PDFé“¾æ¥çš„ExcelæŠ¥å‘Š")

    # ç»Ÿè®¡ä¿¡æ¯
    total_announcements = 0
    total_processed = 0
    total_extracted = 0
    
    # åˆ›å»ºè¿›åº¦ä¿å­˜æ–‡ä»¶ï¼Œé˜²æ­¢æ„å¤–ä¸­æ–­
    progress_file = "crawler_progress.json"
    import json
    
    def save_progress():
        """ä¿å­˜å½“å‰è¿›åº¦"""
        progress_data = {
            "total_announcements": total_announcements,
            "total_processed": total_processed,
            "total_extracted": total_extracted,
            "current_exchange": exchange.get('name', ''),
            "current_date": date_str,
            "timestamp": datetime.now().isoformat()
        }
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def load_progress():
        """åŠ è½½ä¹‹å‰çš„è¿›åº¦"""
        try:
            if os.path.exists(progress_file):
                with open(progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return None
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„è¿›åº¦
    previous_progress = load_progress()
    if previous_progress:
        print(f"\nğŸ”„ å‘ç°ä¹‹å‰çš„è¿›åº¦æ–‡ä»¶:")
        print(f"  ä¸Šæ¬¡å¤„ç†åˆ°: {previous_progress.get('current_exchange', 'æœªçŸ¥')} - {previous_progress.get('current_date', 'æœªçŸ¥')}")
        print(f"  å·²å¤„ç†å…¬å‘Š: {previous_progress.get('total_processed', 0)}")
        print(f"  å·²æå–æ•°æ®: {previous_progress.get('total_extracted', 0)}")
        print(f"  æ—¶é—´æˆ³: {previous_progress.get('timestamp', 'æœªçŸ¥')}")
        
        choice = input("\næ˜¯å¦ç»§ç»­ä¹‹å‰çš„è¿›åº¦ï¼Ÿ(y/n): ").strip().lower()
        if choice == 'y':
            total_announcements = previous_progress.get('total_announcements', 0)
            total_processed = previous_progress.get('total_processed', 0)
            total_extracted = previous_progress.get('total_extracted', 0)
            print("âœ… ç»§ç»­ä¹‹å‰çš„è¿›åº¦...")
        else:
            print("ğŸ†• å¼€å§‹æ–°çš„çˆ¬å–ä»»åŠ¡...")
    
    # éå†æ¯ä¸ªäº¤æ˜“æ‰€
    for exchange in exchanges:
        print(f"\n{'='*50}")
        print(f"å¼€å§‹çˆ¬å– {exchange['name']} ({exchange['column']})")
        print(f"{'='*50}")
        
        exchange_announcements = 0
        exchange_processed = 0
        exchange_extracted = 0
        
        # éå†æ¯ä¸ªæ—¥æœŸ
        for date_str in date_list:
            print(f"\n===== å¼€å§‹å¤„ç†æ—¥æœŸ: {date_str} =====")
            
            # ä½¿ç”¨å¤šAPIæ¥å£è·å–å…¬å‘Šæ•°æ®
            print(f"ğŸ” æ­£åœ¨ä» {len(api_urls)} ä¸ªAPIæ¥å£è·å– {exchange['name']} çš„å…¬å‘Šæ•°æ®...")
            announcements = get_announcements_multi_api(
                session, headers, exchange, date_str, report_categories, api_urls
            )
            
            if not announcements:
                print(f"ğŸ“­ æ—¥æœŸ {date_str} æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å…¬å‘Šï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ—¥æœŸ...")
                continue
            
            print(f"ğŸ“Š é€šè¿‡å¤šAPIæ¥å£è·å–åˆ° {len(announcements)} ä¸ªå…¬å‘Š")
            exchange_announcements += len(announcements)
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºå‰å‡ ä¸ªå…¬å‘Šçš„æ ‡é¢˜
            if len(announcements) > 0:
                print("ğŸ“‹ å‰3ä¸ªå…¬å‘Šæ ‡é¢˜:")
                for i, ann in enumerate(announcements[:3]):
                    title = ann.get('announcementTitle', 'æœªçŸ¥æ ‡é¢˜')
                    print(f"  {i+1}. {title}")
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
            with ThreadPoolExecutor(max_workers=5) as executor:
                future_to_info = {
                    executor.submit(process_announcement, ann, session, headers, folder_path, download_pdf): ann 
                    for ann in announcements
                }
                for future in as_completed(future_to_info):
                    try:
                        extracted_data = future.result()
                        if extracted_data:
                            all_results_for_excel.extend(extracted_data)
                            exchange_processed += 1
                            if any(item.get('é¡¹ç›®åç§°') != 'æœªæ‰¾åˆ°' for item in extracted_data):
                                exchange_extracted += 1
                    except Exception as exc:
                        print(f'ä¸€ä¸ªä»»åŠ¡åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {exc}')
            
            print(f"âœ… æ—¥æœŸ {date_str} å¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(announcements)} ä¸ªå…¬å‘Š")
            
            # ä¿å­˜è¿›åº¦
            save_progress()
        
        # äº¤æ˜“æ‰€ç»Ÿè®¡
        print(f"\nğŸ“ˆ {exchange['name']} ç»Ÿè®¡:")
        print(f"  æ€»å…¬å‘Šæ•°: {exchange_announcements}")
        print(f"  æˆåŠŸå¤„ç†: {exchange_processed}")
        print(f"  æˆåŠŸæå–æ•°æ®: {exchange_extracted}")
        
        total_announcements += exchange_announcements
        total_processed += exchange_processed
        total_extracted += exchange_extracted
    
    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ¯ 2025å¹´åŠå¹´æŠ¥æ•°æ®ç»Ÿè®¡:")
    print(f"  ğŸ“Š æ€»å…¬å‘Šæ•°: {total_announcements}")
    print(f"  âœ… æˆåŠŸå¤„ç†: {total_processed}")
    print(f"  ğŸ’ æˆåŠŸæå–æ•°æ®: {total_extracted}")
    print(f"  ğŸ“ˆ æ•°æ®æå–ç‡: {(total_extracted/total_processed*100):.1f}%" if total_processed > 0 else "  ğŸ“ˆ æ•°æ®æå–ç‡: 0%")
    print(f"  ğŸ—“ï¸ æ•°æ®å¹´ä»½: ä¸¥æ ¼é™åˆ¶ä¸º2025å¹´")
    
    # ç”Ÿæˆæœ€ç»ˆçš„ExcelæŠ¥å‘Š
    print("\n===== å…¨éƒ¨æ—¥æœŸå¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”ŸæˆExcelæŠ¥å‘Š... =====")
    if all_results_for_excel:
        df = pd.DataFrame(all_results_for_excel)
        df = df[['è¯åˆ¸ä»£ç ', 'å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'é¡¹ç›®åç§°', 'é‡‘é¢', 'äººå·¥æ£€æµ‹', 'æŠ¥å‘Šæ—¥æœŸ', 'PDFé“¾æ¥']]
        
        # æœ€ç»ˆå»é‡å¤„ç†
        print("æ­£åœ¨è¿›è¡Œæœ€ç»ˆæ•°æ®å»é‡...")
        original_count = len(df)
        df = df.drop_duplicates(subset=['å…¬å¸åç§°', 'æŠ¥å‘Šåç§°', 'é¡¹ç›®åç§°'], keep='first')
        final_count = len(df)
        print(f"å»é‡å‰: {original_count} è¡Œï¼Œå»é‡å: {final_count} è¡Œï¼Œå»é™¤äº† {original_count - final_count} è¡Œé‡å¤æ•°æ®")
        
        output_filename = 'æ•°æ®èµ„æºæå–ç»“æœ.xlsx'
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
        if os.path.exists(output_filename):
            os.remove(output_filename)
            print(f"å·²åˆ é™¤æ—§çš„ {output_filename} æ–‡ä»¶")
        
        df.to_excel(output_filename, index=False)
        print(f"ğŸ‰ é•¿æ ¼å¼æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ï¼å·²ä¿å­˜ä¸º ./{output_filename}")
        
        # ç”Ÿæˆå®½æ ¼å¼æŠ¥å‘Š
        print("\næ­£åœ¨ç”Ÿæˆå®½æ ¼å¼æŠ¥å‘Š...")
        pivot_financial_data(output_filename, 'æœ€ç»ˆå®½æ ¼å¼æŠ¥å‘Š.xlsx')
    else:
        print("æœªæå–åˆ°ä»»ä½•æ•°æ®ï¼Œä¸ç”ŸæˆExcelæ–‡ä»¶ã€‚")
        
    end_time = time.time()
    print(f"æ€»è€—æ—¶: {(end_time - start_time):.2f} ç§’")
    
    # æ¸…ç†è¿›åº¦æ–‡ä»¶
    if os.path.exists(progress_file):
        os.remove(progress_file)
        print("ğŸ§¹ å·²æ¸…ç†è¿›åº¦æ–‡ä»¶")


if __name__ == "__main__":
    print("=" * 60)
    print("è´¢åŠ¡æ•°æ®çˆ¬è™« - ä¸Šå¸‚å…¬å¸æ•°æ®èµ„æºæå–å·¥å…· (å¢å¼ºç‰ˆ)")
    print("=" * 60)
    print("åŠŸèƒ½ï¼šä»å·¨æ½®èµ„è®¯ç½‘çˆ¬å–è´¢åŠ¡æŠ¥å‘Šä¸­çš„'æ•°æ®èµ„æº'ä¿¡æ¯")
    print("è¾“å‡ºï¼šç”Ÿæˆé•¿æ ¼å¼å’Œå®½æ ¼å¼çš„ExcelæŠ¥å‘Š")
    print("")
    print("ğŸš€ å¢å¼ºç‰¹æ€§ï¼š")
    print("  âœ… æ”¯æŒ5ä¸ªäº¤æ˜“æ‰€ï¼šä¸Šäº¤æ‰€ã€æ·±äº¤æ‰€ã€åŒ—äº¤æ‰€ã€æ–°ä¸‰æ¿ã€ç§‘åˆ›æ¿")
    print("  âœ… ä¸¥æ ¼é™åˆ¶2025å¹´åŠå¹´æŠ¥æ•°æ®ï¼ˆè·³è¿‡2021ã€2022ã€2023ã€2024å¹´ï¼‰")
    print("  âœ… ä½¿ç”¨3ä¸ªAPIæ¥å£ç¡®ä¿æ•°æ®å®Œæ•´æ€§")
    print("  âœ… æ™ºèƒ½å»é‡é¿å…é‡å¤æ•°æ®")
    print("  âœ… è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º")
    print("=" * 60)
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print("  python financial_data_crawler.py y    # ä¸‹è½½PDFå¹¶ç”ŸæˆExcel")
    print("  python financial_data_crawler.py n    # ä»…ç”ŸæˆExcelæ•°æ®")
    print("  python financial_data_crawler.py      # äº¤äº’å¼é€‰æ‹©")
    print("=" * 60)
    
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nç¨‹åºæ‰§è¡Œå®Œæ¯•")
